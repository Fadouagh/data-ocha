{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tuning hyperparameters\n",
    "\n",
    "Author: Fadoua Ghourabi (fadouaghourabi@gmail.com)\n",
    "\n",
    "Date: June 27, 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import uniform\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import Ridge, LinearRegression, LogisticRegression\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross validation\n",
    "\n",
    "Recall cross validation from the session _linear models_. Instead of splitting the data into one train set and one test set, cross validation splits data repeatedly and multiple models are trained. The most common cross validation is K-fold cross validation. When performing K-fold, the model is trained and tested on K partitions of the dats. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross validation score: [1.         0.96666667 0.93333333 0.9        1.        ]\n",
      "Cross validation mean score: 0.9600000000000002\n",
      "Cross validation std score: 0.038873012632301994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "iris = datasets.load_iris()\n",
    "model = LogisticRegression()\n",
    "\n",
    "# Perform 5-fold cross validation, i.e. cv = 5\n",
    "scores = cross_val_score(model, iris.data, iris.target, cv=5, scoring='accuracy')\n",
    "print(\"Cross validation score: {}\".format(scores))\n",
    "print(\"Cross validation mean score: {}\".format(scores.mean()))\n",
    "print(\"Cross validation std score: {}\".format(scores.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``cross_val_score`` computes the scores of the test sets. Since it is a classification problem, the score function is the mean accuracy on the given test set.\n",
    "$$\\text{accuracy} = \\frac{\\text{# correct predictions}}{\\text{# of target values}}$$\n",
    "\n",
    "**Ohno san asks \"How do I know whether the model is overfitting or underfitting?\".** In other words, how do I get the score of the training set so that we can compare with the score of the test set? Unfortunately, ``cross_val_score`` does not give such information, but we can get it manually as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_fitting_KFold(model, X, y, kfold):\n",
    "    train_scores, test_scores = [], []\n",
    "    cv = KFold(kfold) # split into k partitions of train and test sets\n",
    "    \n",
    "    # for each partition, we compute the train score and test score\n",
    "    for train, test in cv.split(X):\n",
    "        model.fit(X[train], y[train])\n",
    "        train_scores.append(model.score(X[train], y[train]))\n",
    "        test_scores.append(model.score(X[test], y[test]))\n",
    "\n",
    "    mean_train_score = np.mean(train_scores)\n",
    "    mean_test_score = np.mean(test_scores)\n",
    "    \n",
    "    return mean_train_score, mean_test_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.9316666666666666, 0.7533333333333333)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_fitting_KFold(LogisticRegression(), iris.data, iris.target, 5) # overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "boston = datasets.load_boston()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9825743779053129, 0.5765448987355657)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_fitting_KFold(GradientBoostingRegressor(), boston.data, boston.target, 3) # overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetes = datasets.load_diabetes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.4210754013322908, 0.40942743830329875)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_fitting_KFold(Ridge(), diabetes.data, diabetes.target, 3) # very bad model: overfitting & underfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid search with cross validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grid search is an approach to hyperparameter tuning that will evaluate a model for each combination of algorithm hyperparameters specified in a grid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['alpha', 'copy_X', 'fit_intercept', 'max_iter', 'normalize', 'random_state', 'solver', 'tol'])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ridge().get_params().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.603264372336529\n",
      "100.0\n",
      "saga\n",
      "Ridge(alpha=100.0, copy_X=True, fit_intercept=True, max_iter=None,\n",
      "      normalize=False, random_state=None, solver='saga', tol=0.001)\n"
     ]
    }
   ],
   "source": [
    "#dataset = datasets.load_diabetes()\n",
    "dataset = datasets.load_boston()\n",
    "\n",
    "# a range of alpha values to test\n",
    "alphas = np.array([0.1,0.5,1,10,100])\n",
    "\n",
    "# a range of solvers\n",
    "solver = ['sag', 'saga','svd','sparse_cg','lsqr','cholesky']\n",
    "param_grid = {'alpha': alphas, 'solver': solver}\n",
    "\n",
    "# create and fit a ridge regression model\n",
    "model = Ridge()\n",
    "\n",
    "# test the model on diffrent alphas and solvers\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, scoring='r2', cv=2)\n",
    "grid.fit(dataset.data, dataset.target)\n",
    "\n",
    "# summarize the results of the grid search\n",
    "print(grid.best_score_)\n",
    "print(grid.best_estimator_.alpha)\n",
    "print(grid.best_estimator_.solver)\n",
    "print(grid.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5911192572696201"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_estimator_.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_alpha</th>\n",
       "      <th>param_solver</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.023444</td>\n",
       "      <td>0.005610</td>\n",
       "      <td>0.000455</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.1</td>\n",
       "      <td>sag</td>\n",
       "      <td>{'alpha': 0.1, 'solver': 'sag'}</td>\n",
       "      <td>0.597338</td>\n",
       "      <td>0.414181</td>\n",
       "      <td>0.505760</td>\n",
       "      <td>0.091579</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.035548</td>\n",
       "      <td>0.010256</td>\n",
       "      <td>0.000533</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>0.1</td>\n",
       "      <td>saga</td>\n",
       "      <td>{'alpha': 0.1, 'solver': 'saga'}</td>\n",
       "      <td>0.602580</td>\n",
       "      <td>0.563901</td>\n",
       "      <td>0.583240</td>\n",
       "      <td>0.019340</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.002903</td>\n",
       "      <td>0.001993</td>\n",
       "      <td>0.000603</td>\n",
       "      <td>0.000040</td>\n",
       "      <td>0.1</td>\n",
       "      <td>svd</td>\n",
       "      <td>{'alpha': 0.1, 'solver': 'svd'}</td>\n",
       "      <td>0.609503</td>\n",
       "      <td>-1.922376</td>\n",
       "      <td>-0.656436</td>\n",
       "      <td>1.265940</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.001420</td>\n",
       "      <td>0.000216</td>\n",
       "      <td>0.000501</td>\n",
       "      <td>0.000124</td>\n",
       "      <td>0.1</td>\n",
       "      <td>sparse_cg</td>\n",
       "      <td>{'alpha': 0.1, 'solver': 'sparse_cg'}</td>\n",
       "      <td>0.555546</td>\n",
       "      <td>-0.671501</td>\n",
       "      <td>-0.057977</td>\n",
       "      <td>0.613524</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.001697</td>\n",
       "      <td>0.000290</td>\n",
       "      <td>0.000369</td>\n",
       "      <td>0.000076</td>\n",
       "      <td>0.1</td>\n",
       "      <td>lsqr</td>\n",
       "      <td>{'alpha': 0.1, 'solver': 'lsqr'}</td>\n",
       "      <td>0.555542</td>\n",
       "      <td>-0.671501</td>\n",
       "      <td>-0.057980</td>\n",
       "      <td>0.613521</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.000742</td>\n",
       "      <td>0.000206</td>\n",
       "      <td>0.000370</td>\n",
       "      <td>0.000059</td>\n",
       "      <td>0.1</td>\n",
       "      <td>cholesky</td>\n",
       "      <td>{'alpha': 0.1, 'solver': 'cholesky'}</td>\n",
       "      <td>0.609503</td>\n",
       "      <td>-1.922376</td>\n",
       "      <td>-0.656436</td>\n",
       "      <td>1.265940</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.027872</td>\n",
       "      <td>0.010077</td>\n",
       "      <td>0.000485</td>\n",
       "      <td>0.000091</td>\n",
       "      <td>0.5</td>\n",
       "      <td>sag</td>\n",
       "      <td>{'alpha': 0.5, 'solver': 'sag'}</td>\n",
       "      <td>0.596884</td>\n",
       "      <td>0.416739</td>\n",
       "      <td>0.506811</td>\n",
       "      <td>0.090072</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.041539</td>\n",
       "      <td>0.009535</td>\n",
       "      <td>0.000619</td>\n",
       "      <td>0.000071</td>\n",
       "      <td>0.5</td>\n",
       "      <td>saga</td>\n",
       "      <td>{'alpha': 0.5, 'solver': 'saga'}</td>\n",
       "      <td>0.602732</td>\n",
       "      <td>0.563821</td>\n",
       "      <td>0.583276</td>\n",
       "      <td>0.019455</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.001404</td>\n",
       "      <td>0.000510</td>\n",
       "      <td>0.000433</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.5</td>\n",
       "      <td>svd</td>\n",
       "      <td>{'alpha': 0.5, 'solver': 'svd'}</td>\n",
       "      <td>0.604466</td>\n",
       "      <td>-1.298929</td>\n",
       "      <td>-0.347232</td>\n",
       "      <td>0.951698</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.001756</td>\n",
       "      <td>0.000165</td>\n",
       "      <td>0.000439</td>\n",
       "      <td>0.000078</td>\n",
       "      <td>0.5</td>\n",
       "      <td>sparse_cg</td>\n",
       "      <td>{'alpha': 0.5, 'solver': 'sparse_cg'}</td>\n",
       "      <td>0.555709</td>\n",
       "      <td>-0.651947</td>\n",
       "      <td>-0.048119</td>\n",
       "      <td>0.603828</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.002013</td>\n",
       "      <td>0.000346</td>\n",
       "      <td>0.000550</td>\n",
       "      <td>0.000211</td>\n",
       "      <td>0.5</td>\n",
       "      <td>lsqr</td>\n",
       "      <td>{'alpha': 0.5, 'solver': 'lsqr'}</td>\n",
       "      <td>0.555708</td>\n",
       "      <td>-0.651947</td>\n",
       "      <td>-0.048120</td>\n",
       "      <td>0.603827</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.000643</td>\n",
       "      <td>0.000141</td>\n",
       "      <td>0.000370</td>\n",
       "      <td>0.000079</td>\n",
       "      <td>0.5</td>\n",
       "      <td>cholesky</td>\n",
       "      <td>{'alpha': 0.5, 'solver': 'cholesky'}</td>\n",
       "      <td>0.604466</td>\n",
       "      <td>-1.298929</td>\n",
       "      <td>-0.347232</td>\n",
       "      <td>0.951698</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.050179</td>\n",
       "      <td>0.025391</td>\n",
       "      <td>0.000583</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>1</td>\n",
       "      <td>sag</td>\n",
       "      <td>{'alpha': 1.0, 'solver': 'sag'}</td>\n",
       "      <td>0.597154</td>\n",
       "      <td>0.418927</td>\n",
       "      <td>0.508041</td>\n",
       "      <td>0.089114</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.039792</td>\n",
       "      <td>0.010164</td>\n",
       "      <td>0.000430</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>1</td>\n",
       "      <td>saga</td>\n",
       "      <td>{'alpha': 1.0, 'solver': 'saga'}</td>\n",
       "      <td>0.602642</td>\n",
       "      <td>0.564197</td>\n",
       "      <td>0.583420</td>\n",
       "      <td>0.019223</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.001106</td>\n",
       "      <td>0.000296</td>\n",
       "      <td>0.000543</td>\n",
       "      <td>0.000110</td>\n",
       "      <td>1</td>\n",
       "      <td>svd</td>\n",
       "      <td>{'alpha': 1.0, 'solver': 'svd'}</td>\n",
       "      <td>0.597372</td>\n",
       "      <td>-1.000581</td>\n",
       "      <td>-0.201604</td>\n",
       "      <td>0.798977</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.001445</td>\n",
       "      <td>0.000085</td>\n",
       "      <td>0.000404</td>\n",
       "      <td>0.000106</td>\n",
       "      <td>1</td>\n",
       "      <td>sparse_cg</td>\n",
       "      <td>{'alpha': 1.0, 'solver': 'sparse_cg'}</td>\n",
       "      <td>0.555923</td>\n",
       "      <td>-0.628160</td>\n",
       "      <td>-0.036118</td>\n",
       "      <td>0.592042</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.001705</td>\n",
       "      <td>0.000240</td>\n",
       "      <td>0.000516</td>\n",
       "      <td>0.000215</td>\n",
       "      <td>1</td>\n",
       "      <td>lsqr</td>\n",
       "      <td>{'alpha': 1.0, 'solver': 'lsqr'}</td>\n",
       "      <td>0.555915</td>\n",
       "      <td>-0.628160</td>\n",
       "      <td>-0.036122</td>\n",
       "      <td>0.592037</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.000458</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>0.000297</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>1</td>\n",
       "      <td>cholesky</td>\n",
       "      <td>{'alpha': 1.0, 'solver': 'cholesky'}</td>\n",
       "      <td>0.597372</td>\n",
       "      <td>-1.000581</td>\n",
       "      <td>-0.201604</td>\n",
       "      <td>0.798977</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.026914</td>\n",
       "      <td>0.008883</td>\n",
       "      <td>0.000518</td>\n",
       "      <td>0.000081</td>\n",
       "      <td>10</td>\n",
       "      <td>sag</td>\n",
       "      <td>{'alpha': 10.0, 'solver': 'sag'}</td>\n",
       "      <td>0.597905</td>\n",
       "      <td>0.445123</td>\n",
       "      <td>0.521514</td>\n",
       "      <td>0.076391</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.037183</td>\n",
       "      <td>0.005901</td>\n",
       "      <td>0.000641</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>10</td>\n",
       "      <td>saga</td>\n",
       "      <td>{'alpha': 10.0, 'solver': 'saga'}</td>\n",
       "      <td>0.602780</td>\n",
       "      <td>0.570849</td>\n",
       "      <td>0.586814</td>\n",
       "      <td>0.015965</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.000600</td>\n",
       "      <td>0.000077</td>\n",
       "      <td>0.000294</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>10</td>\n",
       "      <td>svd</td>\n",
       "      <td>{'alpha': 10.0, 'solver': 'svd'}</td>\n",
       "      <td>0.592827</td>\n",
       "      <td>-0.284025</td>\n",
       "      <td>0.154401</td>\n",
       "      <td>0.438426</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.001871</td>\n",
       "      <td>0.000082</td>\n",
       "      <td>0.000382</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>10</td>\n",
       "      <td>sparse_cg</td>\n",
       "      <td>{'alpha': 10.0, 'solver': 'sparse_cg'}</td>\n",
       "      <td>0.559502</td>\n",
       "      <td>-0.296996</td>\n",
       "      <td>0.131253</td>\n",
       "      <td>0.428249</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.002007</td>\n",
       "      <td>0.000411</td>\n",
       "      <td>0.000613</td>\n",
       "      <td>0.000074</td>\n",
       "      <td>10</td>\n",
       "      <td>lsqr</td>\n",
       "      <td>{'alpha': 10.0, 'solver': 'lsqr'}</td>\n",
       "      <td>0.559497</td>\n",
       "      <td>-0.296848</td>\n",
       "      <td>0.131325</td>\n",
       "      <td>0.428172</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.000774</td>\n",
       "      <td>0.000071</td>\n",
       "      <td>0.000462</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>10</td>\n",
       "      <td>cholesky</td>\n",
       "      <td>{'alpha': 10.0, 'solver': 'cholesky'}</td>\n",
       "      <td>0.592827</td>\n",
       "      <td>-0.284025</td>\n",
       "      <td>0.154401</td>\n",
       "      <td>0.438426</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.022336</td>\n",
       "      <td>0.003572</td>\n",
       "      <td>0.000563</td>\n",
       "      <td>0.000181</td>\n",
       "      <td>100</td>\n",
       "      <td>sag</td>\n",
       "      <td>{'alpha': 100.0, 'solver': 'sag'}</td>\n",
       "      <td>0.602790</td>\n",
       "      <td>0.569591</td>\n",
       "      <td>0.586191</td>\n",
       "      <td>0.016599</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.035234</td>\n",
       "      <td>0.004575</td>\n",
       "      <td>0.000589</td>\n",
       "      <td>0.000139</td>\n",
       "      <td>100</td>\n",
       "      <td>saga</td>\n",
       "      <td>{'alpha': 100.0, 'solver': 'saga'}</td>\n",
       "      <td>0.602715</td>\n",
       "      <td>0.603813</td>\n",
       "      <td>0.603264</td>\n",
       "      <td>0.000549</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.000887</td>\n",
       "      <td>0.000312</td>\n",
       "      <td>0.000309</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>100</td>\n",
       "      <td>svd</td>\n",
       "      <td>{'alpha': 100.0, 'solver': 'svd'}</td>\n",
       "      <td>0.603165</td>\n",
       "      <td>0.471518</td>\n",
       "      <td>0.537341</td>\n",
       "      <td>0.065824</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.001307</td>\n",
       "      <td>0.000287</td>\n",
       "      <td>0.000373</td>\n",
       "      <td>0.000084</td>\n",
       "      <td>100</td>\n",
       "      <td>sparse_cg</td>\n",
       "      <td>{'alpha': 100.0, 'solver': 'sparse_cg'}</td>\n",
       "      <td>0.583982</td>\n",
       "      <td>0.469690</td>\n",
       "      <td>0.526836</td>\n",
       "      <td>0.057146</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.002599</td>\n",
       "      <td>0.000170</td>\n",
       "      <td>0.000414</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>100</td>\n",
       "      <td>lsqr</td>\n",
       "      <td>{'alpha': 100.0, 'solver': 'lsqr'}</td>\n",
       "      <td>0.583975</td>\n",
       "      <td>0.392768</td>\n",
       "      <td>0.488371</td>\n",
       "      <td>0.095603</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.000757</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.000547</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>100</td>\n",
       "      <td>cholesky</td>\n",
       "      <td>{'alpha': 100.0, 'solver': 'cholesky'}</td>\n",
       "      <td>0.603165</td>\n",
       "      <td>0.471518</td>\n",
       "      <td>0.537341</td>\n",
       "      <td>0.065824</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time param_alpha  \\\n",
       "0        0.023444      0.005610         0.000455        0.000010         0.1   \n",
       "1        0.035548      0.010256         0.000533        0.000023         0.1   \n",
       "2        0.002903      0.001993         0.000603        0.000040         0.1   \n",
       "3        0.001420      0.000216         0.000501        0.000124         0.1   \n",
       "4        0.001697      0.000290         0.000369        0.000076         0.1   \n",
       "5        0.000742      0.000206         0.000370        0.000059         0.1   \n",
       "6        0.027872      0.010077         0.000485        0.000091         0.5   \n",
       "7        0.041539      0.009535         0.000619        0.000071         0.5   \n",
       "8        0.001404      0.000510         0.000433        0.000004         0.5   \n",
       "9        0.001756      0.000165         0.000439        0.000078         0.5   \n",
       "10       0.002013      0.000346         0.000550        0.000211         0.5   \n",
       "11       0.000643      0.000141         0.000370        0.000079         0.5   \n",
       "12       0.050179      0.025391         0.000583        0.000020           1   \n",
       "13       0.039792      0.010164         0.000430        0.000013           1   \n",
       "14       0.001106      0.000296         0.000543        0.000110           1   \n",
       "15       0.001445      0.000085         0.000404        0.000106           1   \n",
       "16       0.001705      0.000240         0.000516        0.000215           1   \n",
       "17       0.000458      0.000021         0.000297        0.000013           1   \n",
       "18       0.026914      0.008883         0.000518        0.000081          10   \n",
       "19       0.037183      0.005901         0.000641        0.000033          10   \n",
       "20       0.000600      0.000077         0.000294        0.000004          10   \n",
       "21       0.001871      0.000082         0.000382        0.000008          10   \n",
       "22       0.002007      0.000411         0.000613        0.000074          10   \n",
       "23       0.000774      0.000071         0.000462        0.000004          10   \n",
       "24       0.022336      0.003572         0.000563        0.000181         100   \n",
       "25       0.035234      0.004575         0.000589        0.000139         100   \n",
       "26       0.000887      0.000312         0.000309        0.000014         100   \n",
       "27       0.001307      0.000287         0.000373        0.000084         100   \n",
       "28       0.002599      0.000170         0.000414        0.000069         100   \n",
       "29       0.000757      0.000020         0.000547        0.000002         100   \n",
       "\n",
       "   param_solver                                   params  split0_test_score  \\\n",
       "0           sag          {'alpha': 0.1, 'solver': 'sag'}           0.597338   \n",
       "1          saga         {'alpha': 0.1, 'solver': 'saga'}           0.602580   \n",
       "2           svd          {'alpha': 0.1, 'solver': 'svd'}           0.609503   \n",
       "3     sparse_cg    {'alpha': 0.1, 'solver': 'sparse_cg'}           0.555546   \n",
       "4          lsqr         {'alpha': 0.1, 'solver': 'lsqr'}           0.555542   \n",
       "5      cholesky     {'alpha': 0.1, 'solver': 'cholesky'}           0.609503   \n",
       "6           sag          {'alpha': 0.5, 'solver': 'sag'}           0.596884   \n",
       "7          saga         {'alpha': 0.5, 'solver': 'saga'}           0.602732   \n",
       "8           svd          {'alpha': 0.5, 'solver': 'svd'}           0.604466   \n",
       "9     sparse_cg    {'alpha': 0.5, 'solver': 'sparse_cg'}           0.555709   \n",
       "10         lsqr         {'alpha': 0.5, 'solver': 'lsqr'}           0.555708   \n",
       "11     cholesky     {'alpha': 0.5, 'solver': 'cholesky'}           0.604466   \n",
       "12          sag          {'alpha': 1.0, 'solver': 'sag'}           0.597154   \n",
       "13         saga         {'alpha': 1.0, 'solver': 'saga'}           0.602642   \n",
       "14          svd          {'alpha': 1.0, 'solver': 'svd'}           0.597372   \n",
       "15    sparse_cg    {'alpha': 1.0, 'solver': 'sparse_cg'}           0.555923   \n",
       "16         lsqr         {'alpha': 1.0, 'solver': 'lsqr'}           0.555915   \n",
       "17     cholesky     {'alpha': 1.0, 'solver': 'cholesky'}           0.597372   \n",
       "18          sag         {'alpha': 10.0, 'solver': 'sag'}           0.597905   \n",
       "19         saga        {'alpha': 10.0, 'solver': 'saga'}           0.602780   \n",
       "20          svd         {'alpha': 10.0, 'solver': 'svd'}           0.592827   \n",
       "21    sparse_cg   {'alpha': 10.0, 'solver': 'sparse_cg'}           0.559502   \n",
       "22         lsqr        {'alpha': 10.0, 'solver': 'lsqr'}           0.559497   \n",
       "23     cholesky    {'alpha': 10.0, 'solver': 'cholesky'}           0.592827   \n",
       "24          sag        {'alpha': 100.0, 'solver': 'sag'}           0.602790   \n",
       "25         saga       {'alpha': 100.0, 'solver': 'saga'}           0.602715   \n",
       "26          svd        {'alpha': 100.0, 'solver': 'svd'}           0.603165   \n",
       "27    sparse_cg  {'alpha': 100.0, 'solver': 'sparse_cg'}           0.583982   \n",
       "28         lsqr       {'alpha': 100.0, 'solver': 'lsqr'}           0.583975   \n",
       "29     cholesky   {'alpha': 100.0, 'solver': 'cholesky'}           0.603165   \n",
       "\n",
       "    split1_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0            0.414181         0.505760        0.091579               13  \n",
       "1            0.563901         0.583240        0.019340                6  \n",
       "2           -1.922376        -0.656436        1.265940               29  \n",
       "3           -0.671501        -0.057977        0.613524               23  \n",
       "4           -0.671501        -0.057980        0.613521               24  \n",
       "5           -1.922376        -0.656436        1.265940               30  \n",
       "6            0.416739         0.506811        0.090072               12  \n",
       "7            0.563821         0.583276        0.019455                5  \n",
       "8           -1.298929        -0.347232        0.951698               27  \n",
       "9           -0.651947        -0.048119        0.603828               21  \n",
       "10          -0.651947        -0.048120        0.603827               22  \n",
       "11          -1.298929        -0.347232        0.951698               28  \n",
       "12           0.418927         0.508041        0.089114               11  \n",
       "13           0.564197         0.583420        0.019223                4  \n",
       "14          -1.000581        -0.201604        0.798977               25  \n",
       "15          -0.628160        -0.036118        0.592042               19  \n",
       "16          -0.628160        -0.036122        0.592037               20  \n",
       "17          -1.000581        -0.201604        0.798977               26  \n",
       "18           0.445123         0.521514        0.076391               10  \n",
       "19           0.570849         0.586814        0.015965                2  \n",
       "20          -0.284025         0.154401        0.438426               15  \n",
       "21          -0.296996         0.131253        0.428249               18  \n",
       "22          -0.296848         0.131325        0.428172               17  \n",
       "23          -0.284025         0.154401        0.438426               16  \n",
       "24           0.569591         0.586191        0.016599                3  \n",
       "25           0.603813         0.603264        0.000549                1  \n",
       "26           0.471518         0.537341        0.065824                7  \n",
       "27           0.469690         0.526836        0.057146                9  \n",
       "28           0.392768         0.488371        0.095603               14  \n",
       "29           0.471518         0.537341        0.065824                8  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results = pd.DataFrame(grid.cv_results_)\n",
    "display(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Practice.** Find the best score using gradient boosting tree model? Compare with team mates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
       "                          learning_rate=0.1, loss='ls', max_depth=3,\n",
       "                          max_features=None, max_leaf_nodes=None,\n",
       "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                          min_samples_leaf=1, min_samples_split=2,\n",
       "                          min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                          n_iter_no_change=None, presort='auto',\n",
       "                          random_state=None, subsample=1.0, tol=0.0001,\n",
       "                          validation_fraction=0.1, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GradientBoostingRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7594051136079744\n",
      "0.30000000000000004\n",
      "7\n",
      "95\n",
      "GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
      "                          learning_rate=0.30000000000000004, loss='ls',\n",
      "                          max_depth=3, max_features=7, max_leaf_nodes=None,\n",
      "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                          min_samples_leaf=1, min_samples_split=2,\n",
      "                          min_weight_fraction_leaf=0.0, n_estimators=95,\n",
      "                          n_iter_no_change=None, presort='auto',\n",
      "                          random_state=None, subsample=1.0, tol=0.0001,\n",
      "                          validation_fraction=0.1, verbose=0, warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "#dataset = datasets.load_diabetes()\n",
    "dataset = datasets.load_boston()\n",
    "\n",
    "# a range of learning_rates values\n",
    "learning_rates = np.arange(0.1,1,0.1)\n",
    "\n",
    "# a range of number of features to consider when looking for the best split\n",
    "max_features = ['sqrt', 'log2','auto',2,3,5,6,7,8,9,10,11,12]\n",
    "\n",
    "# a range of number of trees\n",
    "n_estimators = np.arange(10,100,5)\n",
    "\n",
    "param_grid = {'learning_rate': learning_rates, 'max_features': max_features, 'n_estimators': n_estimators}\n",
    "\n",
    "# create and fit a Gradient boosting regressor regression model\n",
    "model = GradientBoostingRegressor()\n",
    "\n",
    "# test the model on diffrent alphas and solvers\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, scoring='r2', cv=2)\n",
    "grid.fit(dataset.data, dataset.target)\n",
    "\n",
    "# summarize the results of the grid search\n",
    "print(grid.best_score_)\n",
    "print(grid.best_estimator_.learning_rate)\n",
    "print(grid.best_estimator_.max_features)\n",
    "print(grid.best_estimator_.n_estimators)\n",
    "print(grid.best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random search with cross validation\n",
    "\n",
    "Random search is an approach to parameter tuning that will sample algorithm hyperparameters from a random distribution (i.e. uniform) for a fixed number of iterations. A model is constructed and evaluated for each combination of hyperparameters choice. See: https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.uniform.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4822780849355016\n",
      "0.001008132834983133\n"
     ]
    }
   ],
   "source": [
    "# load the diabetes datasets\n",
    "dataset = datasets.load_diabetes()\n",
    "# alpha is sampled from a uniform distribution\n",
    "rand_params = {'alpha': uniform()}\n",
    "\n",
    "# create and fit a ridge regression model, testing random alpha values\n",
    "model = Ridge()\n",
    "rsearch = RandomizedSearchCV(estimator=model, param_distributions=rand_params, n_iter=100, cv=5)\n",
    "rsearch.fit(dataset.data, dataset.target)\n",
    "\n",
    "# summarize the results of the random parameter search\n",
    "print(rsearch.best_score_)\n",
    "print(rsearch.best_estimator_.alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
