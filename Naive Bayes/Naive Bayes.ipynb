{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes\n",
    "\n",
    "Author: Fadoua Ghourabi (fadouaghourabi@gmail.com)\n",
    "\n",
    "Date: July 10, 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayes Theorem\n",
    "\n",
    "$$P(A|B) = \\frac{P(B|A)P(A)}{P(B)},$$\n",
    "\n",
    "where:\n",
    "- $A$ and $B$ are events with $P(B)\\neq 0$\n",
    "- $P(A|B)$ is a conditional probability: the likelihood of event $A$ occurring given that $B$ is true.\n",
    "- $P(A)$ and $P(B)$ are the probabilities of observing $A$ and $B$ **independently of each other** (**Naive Bayes assumption**).\n",
    "\n",
    "**Example 1.** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather = pd.DataFrame([\n",
    "                        [\"rainy\",\"hot\",\"high\",\"False\",0],\n",
    "                        [\"rainy\",\"hot\",\"high\",\"True\",0],\n",
    "                        [\"cloudy\",\"hot\",\"high\",\"False\",1],\n",
    "                        [\"sunny\",\"mild\",\"high\",\"False\",1],\n",
    "                        [\"sunny\",\"cool\",\"normal\",\"False\",1],\n",
    "                        [\"sunny\",\"cool\",\"normal\",\"True\",0],\n",
    "                        [\"cloudy\",\"cool\",\"normal\",\"True\",0],\n",
    "                        [\"rainy\",\"mild\",\"high\",\"False\",0],\n",
    "                        [\"rainy\",\"cool\",\"normal\",\"False\",1],\n",
    "                        [\"sunny\",\"mild\",\"normal\",\"False\",1],\n",
    "                        [\"rainy\",\"mild\",\"normal\",\"True\",1],\n",
    "                        [\"cloudy\",\"mild\",\"high\",\"True\",1]], columns=[\"condition\",\"temp\",\"humidity\",\"wind\",\"hike\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>condition</th>\n",
       "      <th>temp</th>\n",
       "      <th>humidity</th>\n",
       "      <th>wind</th>\n",
       "      <th>hike</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rainy</td>\n",
       "      <td>hot</td>\n",
       "      <td>high</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rainy</td>\n",
       "      <td>hot</td>\n",
       "      <td>high</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cloudy</td>\n",
       "      <td>hot</td>\n",
       "      <td>high</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sunny</td>\n",
       "      <td>mild</td>\n",
       "      <td>high</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sunny</td>\n",
       "      <td>cool</td>\n",
       "      <td>normal</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>sunny</td>\n",
       "      <td>cool</td>\n",
       "      <td>normal</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>cloudy</td>\n",
       "      <td>cool</td>\n",
       "      <td>normal</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>rainy</td>\n",
       "      <td>mild</td>\n",
       "      <td>high</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>rainy</td>\n",
       "      <td>cool</td>\n",
       "      <td>normal</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>sunny</td>\n",
       "      <td>mild</td>\n",
       "      <td>normal</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>rainy</td>\n",
       "      <td>mild</td>\n",
       "      <td>normal</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>cloudy</td>\n",
       "      <td>mild</td>\n",
       "      <td>high</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   condition  temp humidity   wind  hike\n",
       "0      rainy   hot     high  False     0\n",
       "1      rainy   hot     high   True     0\n",
       "2     cloudy   hot     high  False     1\n",
       "3      sunny  mild     high  False     1\n",
       "4      sunny  cool   normal  False     1\n",
       "5      sunny  cool   normal   True     0\n",
       "6     cloudy  cool   normal   True     0\n",
       "7      rainy  mild     high  False     0\n",
       "8      rainy  cool   normal  False     1\n",
       "9      sunny  mild   normal  False     1\n",
       "10     rainy  mild   normal   True     1\n",
       "11    cloudy  mild     high   True     1"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$P(A|B) = \\frac{P(B|A)P(A)}{P(B)},$$\n",
    "\n",
    "\n",
    "\n",
    "What is $P(y=1|\\text{sunny})$?\n",
    "\n",
    "- $P(\\text{sunny}|y=1) = 3/7$\n",
    "- $P(y=1) = 7/12$\n",
    "- $P(\\text{sunny}) = 4/12$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.75"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p1 = (3/7 * 7/12)/(4/12)\n",
    "p1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is P(y = 0|sunny)?\n",
    "\n",
    "- P(sunny|y=0) = 1/5\n",
    "- P(y = 0) = 5/12\n",
    "- P(sunny) = 4/12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.25"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p0 = (1/5*5/12)/(4/12)\n",
    "p0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given a class variable $y$ and features $x_1, \\cdots, x_n$ that are assumed **mutually independent**, Bayes theorem applied repeatedly gives:\n",
    "$$P(y|x_1,\\cdots,x_n) = \\frac{P(y)P(x_1|y) \\cdots P(x_n|y)}{P(x_1)\\cdots P(x_n)}$$\n",
    "\n",
    "Since the denominator ${P(x_1)\\cdots P(x_n)}$ is a constant, we deduce:\n",
    "$$P(y|x_1,\\cdots,x_n) \\propto P(y)\\Pi_{i=1}^{n}P(x_i|y)$$\n",
    "\n",
    "The classification $\\hat{y}$ of $x_1, \\cdots, x_n$ would be:\n",
    "\n",
    "$$\\hat{y} = \\underset{y}{\\text{argmax}}~P(y)\\Pi_{i=1}^{n}P(x_i|y)$$\n",
    "\n",
    "**Example 2.** Now, suppose weather condition is X =[\"sunny\",\"cool\",\"noraml\",\"True\"], what is its class $\\hat{y}$?\n",
    "\n",
    "$P(y=0|X) \\propto 0.008$\n",
    "- $P(y=0) = 5/12$\n",
    "- $P(\\text{sunny}|y=0) = 1/5$\n",
    "- $P(\\text{cool}|y=0) = 2/5$\n",
    "- $P(\\text{normal}|y=0) = 2/5$\n",
    "- $P(\\text{True}|y=0) = 3/5$\n",
    "\n",
    "$P(y=1|X)  \\propto 0.012$\n",
    "- $P(y=1) = 7/12$\n",
    "- $P(\\text{sunny}|y=1) = 3/7$\n",
    "- $P(\\text{cool}|y=1) = 2/7$\n",
    "- $P(\\text{normal}|y=1) = 4/7$\n",
    "- $P(\\text{True}|y=1) = 2/7$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(5/12)*(1/5)*(2/5)*(2/5)*(3/5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.011661807580174925"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(7/12)*(3/7)*(2/7)*(4/7)*(2/7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gaussian Naive Bayes\n",
    "\n",
    "In Gaussian Naive Bayes, the features are continuous. We assume they are sampled from a Gaussian distribution. The conditional probability is thus defined as follows:\n",
    "\n",
    "$$P(x_i|y) = \\frac{1}{\\sqrt{2\\pi \\sigma_y^{2}}}exp{(-\\frac{(x_i - \\mu_y)^2}{2\\sigma_y^2})}$$\n",
    "\n",
    "$\\mu_y$ is the mean and $\\sigma_y$ is the standard deviation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _iris_dataset:\n",
      "\n",
      "Iris plants dataset\n",
      "--------------------\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "    :Number of Instances: 150 (50 in each of three classes)\n",
      "    :Number of Attributes: 4 numeric, predictive attributes and the class\n",
      "    :Attribute Information:\n",
      "        - sepal length in cm\n",
      "        - sepal width in cm\n",
      "        - petal length in cm\n",
      "        - petal width in cm\n",
      "        - class:\n",
      "                - Iris-Setosa\n",
      "                - Iris-Versicolour\n",
      "                - Iris-Virginica\n",
      "                \n",
      "    :Summary Statistics:\n",
      "\n",
      "    ============== ==== ==== ======= ===== ====================\n",
      "                    Min  Max   Mean    SD   Class Correlation\n",
      "    ============== ==== ==== ======= ===== ====================\n",
      "    sepal length:   4.3  7.9   5.84   0.83    0.7826\n",
      "    sepal width:    2.0  4.4   3.05   0.43   -0.4194\n",
      "    petal length:   1.0  6.9   3.76   1.76    0.9490  (high!)\n",
      "    petal width:    0.1  2.5   1.20   0.76    0.9565  (high!)\n",
      "    ============== ==== ==== ======= ===== ====================\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "    :Class Distribution: 33.3% for each of 3 classes.\n",
      "    :Creator: R.A. Fisher\n",
      "    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\n",
      "    :Date: July, 1988\n",
      "\n",
      "The famous Iris database, first used by Sir R.A. Fisher. The dataset is taken\n",
      "from Fisher's paper. Note that it's the same as in R, but not as in the UCI\n",
      "Machine Learning Repository, which has two wrong data points.\n",
      "\n",
      "This is perhaps the best known database to be found in the\n",
      "pattern recognition literature.  Fisher's paper is a classic in the field and\n",
      "is referenced frequently to this day.  (See Duda & Hart, for example.)  The\n",
      "data set contains 3 classes of 50 instances each, where each class refers to a\n",
      "type of iris plant.  One class is linearly separable from the other 2; the\n",
      "latter are NOT linearly separable from each other.\n",
      "\n",
      ".. topic:: References\n",
      "\n",
      "   - Fisher, R.A. \"The use of multiple measurements in taxonomic problems\"\n",
      "     Annual Eugenics, 7, Part II, 179-188 (1936); also in \"Contributions to\n",
      "     Mathematical Statistics\" (John Wiley, NY, 1950).\n",
      "   - Duda, R.O., & Hart, P.E. (1973) Pattern Classification and Scene Analysis.\n",
      "     (Q327.D83) John Wiley & Sons.  ISBN 0-471-22361-1.  See page 218.\n",
      "   - Dasarathy, B.V. (1980) \"Nosing Around the Neighborhood: A New System\n",
      "     Structure and Classification Rule for Recognition in Partially Exposed\n",
      "     Environments\".  IEEE Transactions on Pattern Analysis and Machine\n",
      "     Intelligence, Vol. PAMI-2, No. 1, 67-71.\n",
      "   - Gates, G.W. (1972) \"The Reduced Nearest Neighbor Rule\".  IEEE Transactions\n",
      "     on Information Theory, May 1972, 431-433.\n",
      "   - See also: 1988 MLC Proceedings, 54-64.  Cheeseman et al\"s AUTOCLASS II\n",
      "     conceptual clustering system finds 3 classes in the data.\n",
      "   - Many, many more ...\n"
     ]
    }
   ],
   "source": [
    "iris = datasets.load_iris()\n",
    "print(iris.DESCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(iris.data, iris.target, stratify=iris.target, random_state=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB(priors=None, var_smoothing=1e-09)"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gnb = GaussianNB()\n",
    "gnb.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set accuracy 0.9553571428571429\n",
      "Test set accuracy 0.9736842105263158\n"
     ]
    }
   ],
   "source": [
    "print(\"Train set accuracy {}\".format(gnb.score(X_train,y_train)))\n",
    "print(\"Test set accuracy {}\".format(gnb.score(X_test,y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.97297297, 3.40810811, 1.44864865, 0.23243243],\n",
       "       [5.96216216, 2.77027027, 4.30810811, 1.34594595],\n",
       "       [6.54473684, 2.92105263, 5.53684211, 2.02368421]])"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gnb.theta_ # $\\mu_y$ or mean of each feature per class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.12143171, 0.11155588, 0.03330899, 0.00813733],\n",
       "       [0.28289263, 0.09073777, 0.20560994, 0.03707816],\n",
       "       [0.43826178, 0.0963989 , 0.31811635, 0.06812327]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gnb.sigma_ # $\\sigma_y$ or variance of each feature per class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.33035714, 0.33035714, 0.33928571])"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gnb.class_prior_ # prior probability of each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9999999900000001"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.33035714+0.33035714+0.33928571"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2])"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gnb.predict(np.array([5.2,0,10.3,0.2]).reshape(1,4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparing the results with other classifiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set accuracy: 0.9642857142857143\n",
      "Test set accuracy: 0.9473684210526315\n"
     ]
    }
   ],
   "source": [
    "clf = KNeighborsClassifier(n_neighbors=2)\n",
    "clf.fit(X_train, y_train)\n",
    "print(\"Train set accuracy: {}\".format(clf.score(X_train, y_train)))\n",
    "print(\"Test set accuracy: {}\".format(clf.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multinomial Naive Bayes\n",
    "\n",
    "Multinomial Naive Bayes is mostly used for text classification problem, i.e whether a text belongs to a category of science, technology, art etc. The classification is based on the frequency of the words present in the text.\n",
    "\n",
    "The distribution of the data is given by $\\theta_y = (\\theta_{y1},\\cdots,\\theta_{yn})$ for each class $y$, where $n$ is the number of features (or the size of vocabulary in text classification) and $\\theta_{yi} = P(x_i|y)$.\n",
    "\n",
    "When features are not present in the learning samples, e.g. words do not appear in the vocabulary of training text, $P(x_i|y)$ is zero. To avoid zero propabilities, the parameters $\\theta_y$ is estimated by a smoothed version of maximum likelihood:\n",
    "$$\\hat{\\theta}_{yi} = \\frac{N_{yi} + \\alpha}{N_y + n\\alpha},$$\n",
    "\n",
    "where:\n",
    "- $N_{yi}$ is the occurrence of feature $i$ in class $y$, e.g. occurrence of $i$th word in class $y$\n",
    "- $N_y = \\sum_{i=1}^n N_{yi}$ is the total occurrence of features. \n",
    "- $\\alpha$ is a smoothing parameter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem. A simple twitter sentiment analysis\n",
    "\n",
    "Twitter sentiment analysis is a classical problem in **natural language processing (NLP)**. The goal is to be able to automatically classify a tweet as a positive or negative tweet sentiment-wise. The classifier needs to be trained and to do that, we use a list of manually classified/labelled tweets. We use  the following 5 positive tweets and 5 negative tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = [('I love this car', 'positive'),\n",
    "          ('This view is amazing', 'positive'),\n",
    "          ('I feel great this morning', 'positive'),\n",
    "          ('I am so excited about the concert', 'positive'),\n",
    "          ('He is my best friend', 'positive'),\n",
    "          ('I do not like this car', 'negative'),\n",
    "          ('This view is horrible', 'negative'),\n",
    "          ('I feel tired this morning', 'negative'),\n",
    "          ('I am not looking forward to the concert', 'negative'),\n",
    "          ('He is my enemy', 'negative')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We preprocess the tweets by converting all words to lower cases and using 1 space as seperator. Our pre-processing step creates uniform and plain text format for easier treatment. For instance, \"Great\", \"great\" and \"GReat\" have to be converted to lower case to be considered equivalent.\n",
    "\n",
    "Be careful! Preprocessing in NLP is composed of several complex steps such as tokenization, removing stopwords and punctuations, lemmatization, stemming... **For simplicity, we only convert into lower cases and split using 1 space separator**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "tw_data = []\n",
    "for (sent, sentiment) in tweets:\n",
    "    # sent.split() extract the words (or tokens) of a tweet\n",
    "    # w.lower() convert each word to lower case\n",
    "    lower_sent = [w.lower() for w in sent.split()] \n",
    "    # \" \".join(lower_sent) joins the words (or tokens) using 1 space\n",
    "    tw_data.append((\" \".join(lower_sent),sentiment))\n",
    "    \n",
    "tw_df = pd.DataFrame(tw_data,columns=[\"tweet\",\"sentiment\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i love this car</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>this view is amazing</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i feel great this morning</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i am so excited about the concert</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>he is my best friend</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>i do not like this car</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>this view is horrible</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>i feel tired this morning</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>i am not looking forward to the concert</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>he is my enemy</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     tweet sentiment\n",
       "0                          i love this car  positive\n",
       "1                     this view is amazing  positive\n",
       "2                i feel great this morning  positive\n",
       "3        i am so excited about the concert  positive\n",
       "4                     he is my best friend  positive\n",
       "5                   i do not like this car  negative\n",
       "6                    this view is horrible  negative\n",
       "7                i feel tired this morning  negative\n",
       "8  i am not looking forward to the concert  negative\n",
       "9                           he is my enemy  negative"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tw_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Bag of words\n",
    "\n",
    "Bag of words is the simplest representation of text using numbers. This model is only concerned with with the occurrence of the word and not where it is placed (i.e. order) in bag. The intuition behind such approach is that similar texts contain similar words.\n",
    "\n",
    "text1 = 'I love this car'\n",
    "text2 = 'This view is amazing'\n",
    "text3 = 'I feel great this morning'\n",
    "text4 = 'I am so excited about the concert'\n",
    "text5 = 'He is my best friend'\n",
    "text6 = 'I do not like this car'\n",
    "text7 = 'This view is horrible'\n",
    "text8 = 'I feel tired this morning'\n",
    "text9 = 'I am not looking forward to the concert'\n",
    "text10 = 'He is my enemy'\n",
    "\n",
    "**Step 1**: Generate vocabulary or the set of unique words/tokens in the text1$\\sim$text10.\n",
    "\n",
    "**Step 2**: Create vector for each text. The length of the vector is the length of the vocabulary and the features are the words of the vocabulary. Wherever a word occurs in a text, 1 is inserted in the corresponding position of text vector. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``CountVectorizer()`` implements bag of words representation. We fit ``CountVectorizer()`` to our data, i.e. text1$\\sim$text10 so that it builds the vocabulary (step 1) and gives an index for each feature (recall features are words in the vocabulary). The create a vector representation for each text, we use ``transform()`` function. The vectors of text1$\\sim$text10 are stacked in a matrix, or rather a sparse matrix (a matrix whose most of its elements are zeros). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function performs step 1 and 2\n",
    "# it returns:\n",
    "# 1. the bag of words model (variable vectorizer) and,\n",
    "# 2. vectors of text1...text10 in a sparce matrix that we convert into dataframe for easier treatment.\n",
    "def bag_of_words_vec(text):\n",
    "    vectorizer = CountVectorizer()\n",
    "    vocabulary=vectorizer.fit(text) \n",
    "    print(vectorizer.vocabulary_,len(vectorizer.vocabulary_)) \n",
    "    doc_term_matrix= vectorizer.transform(text)\n",
    "    return (vectorizer, pd.DataFrame(doc_term_matrix.toarray())) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The vocabulary is composed of 28 words. The bag of words representation is thus of shape 10x28."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'love': 18, 'this': 24, 'car': 4, 'view': 27, 'is': 15, 'amazing': 2, 'feel': 9, 'great': 12, 'morning': 19, 'am': 1, 'so': 22, 'excited': 8, 'about': 0, 'the': 23, 'concert': 5, 'he': 13, 'my': 20, 'best': 3, 'friend': 11, 'do': 6, 'not': 21, 'like': 16, 'horrible': 14, 'tired': 25, 'looking': 17, 'forward': 10, 'to': 26, 'enemy': 7} 28\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0   1   2   3   4   5   6   7   8   9   ...  18  19  20  21  22  23  24  \\\n",
       "0   0   0   0   0   1   0   0   0   0   0  ...   1   0   0   0   0   0   1   \n",
       "1   0   0   1   0   0   0   0   0   0   0  ...   0   0   0   0   0   0   1   \n",
       "2   0   0   0   0   0   0   0   0   0   1  ...   0   1   0   0   0   0   1   \n",
       "3   1   1   0   0   0   1   0   0   1   0  ...   0   0   0   0   1   1   0   \n",
       "4   0   0   0   1   0   0   0   0   0   0  ...   0   0   1   0   0   0   0   \n",
       "5   0   0   0   0   1   0   1   0   0   0  ...   0   0   0   1   0   0   1   \n",
       "6   0   0   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   0   1   \n",
       "7   0   0   0   0   0   0   0   0   0   1  ...   0   1   0   0   0   0   1   \n",
       "8   0   1   0   0   0   1   0   0   0   0  ...   0   0   0   1   0   1   0   \n",
       "9   0   0   0   0   0   0   0   1   0   0  ...   0   0   1   0   0   0   0   \n",
       "\n",
       "   25  26  27  \n",
       "0   0   0   0  \n",
       "1   0   0   1  \n",
       "2   0   0   0  \n",
       "3   0   0   0  \n",
       "4   0   0   0  \n",
       "5   0   0   0  \n",
       "6   0   0   1  \n",
       "7   1   0   0  \n",
       "8   0   1   0  \n",
       "9   0   0   0  \n",
       "\n",
       "[10 rows x 28 columns]"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer, tw_vecs = bag_of_words_vec(tw_df.tweet)\n",
    "tw_vecs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Practice.** Pick a vector and check whether the representation is correct."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 3** Now we are ready for applying classification algorithm. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We fit ``MultinomialNB`` to the data with the default smoothing alpha equal to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnb = MultinomialNB()\n",
    "mnb.fit(tw_vecs,tw_df.sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5., 5.])"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnb.class_count_ # count of data in each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnb.alpha # value of alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=0.01, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnb = MultinomialNB(alpha=0.01)\n",
    "mnb.fit(tw_vecs,tw_df.sentiment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose we receive three new tweets that we want to classify _positive_ or _negative_. We first transform them using the same bag of words representation that we fit in text1$\\sim$text10. We use ``transform`` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_tweets = vectorizer.transform([\"the cake is good\",\n",
    "                                   \"amazing song\",\n",
    "                                   \"i am not happy about the result\",\n",
    "                                   \"hope always\"]).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "        0, 1, 0, 0, 0, 0],\n",
       "       [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0],\n",
       "       [1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "        0, 1, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we predict the sentiments of the the new tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['positive', 'positive', 'negative', 'negative'], dtype='<U8')"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnb.predict(new_tweets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bernoulli Naive Bayes\n",
    "\n",
    "The Bernoulli Naive Bayes classifier assumes that the data is binary and counts how often every feature of each class is not zero. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['positive', 'positive', 'negative', 'positive'], dtype='<U8')"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bnb = BernoulliNB()\n",
    "bnb.fit(tw_vecs,tw_df.sentiment)\n",
    "bnb.predict(new_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
