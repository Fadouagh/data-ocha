{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision trees\n",
    "Author: Fadoua Ghourabi (fadouaghourabi@gmail.com)\n",
    "\n",
    "Date: June 20, 2019"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Warm-up practice.** \n",
    "1. I pick one animal among _dolphin_, _bear_, _owl_, _penguin_. Your goal is the guess which animal I picked by asking yes/no questions. \n",
    "2. Familiarize yourself with common terminology of binary trees, e.g. **root**, **node**, **leaf**, **depth**, **child node**, **parent node**, etc. \n",
    "\n",
    "A decision tree is a binary tree that splits the dataset into subset by performing a simpe if/else test. It is used for both classification and regression. We first explain the classification with a decision tree."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### An example to start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.datasets import load_breast_cancer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cancer = load_breast_cancer()\n",
    "print(cancer.DESCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cancer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.DataFrame(cancer.data, columns=cancer.feature_names)\n",
    "y = pd.DataFrame(cancer.target, columns=[\"Type\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, random_state=412)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = DecisionTreeClassifier(random_state=12)\n",
    "tree.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_score = tree.score(X_train,y_train)\n",
    "test_score = tree.score(X_test,y_test)\n",
    "print(\"Score of train set: {}\".format(train_score))\n",
    "print(\"Score of test set: {}\".format(test_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pruning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy of the training set is 100%. The tree was grown deep enough that each leaf is **pure**, in other words, it contains one class. This situation is overfitting (test score << train score). We restrict the depth of a decision tree to improve the model, which is called **pruning**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = DecisionTreeClassifier(max_depth=4, random_state=12)\n",
    "tree.fit(X_train, y_train)\n",
    "y_pred = tree.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_score = tree.score(X_train,y_train)\n",
    "test_score = tree.score(X_test,y_test)\n",
    "print(\"Score of train set: {}\".format(train_score))\n",
    "print(\"Score of test set: {}\".format(test_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can visualize the decision tree using ``export_graphviz``. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import export_graphviz\n",
    "export_graphviz(tree, out_file=\"tree.dot\", class_names=[\"malignant\", \"benign\"],\n",
    "                feature_names=cancer.feature_names, impurity=False, filled=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import graphviz\n",
    "\n",
    "with open(\"tree.dot\") as f:\n",
    "    dot_graph = f.read()\n",
    "display(graphviz.Source(dot_graph))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each node includes the following information:\n",
    "- The splitting feature, e.g. root splits the data to (``worst concave points <= 0.147``) and (``worst concave points > 0.147``)\n",
    "- ``samples`` is the count of input samples\n",
    "- ``value`` is the output, or the count of samples in each class. For instance, ``value = [23, 263]`` means 23 samples belong to class malignant and 263 samples to class benign.\n",
    "- ``class`` indicates the dominant class. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Practice.** Change the depth. What do you observe?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Impurity metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gini index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **gini index** is a metric that quantifies the purity of a node or a leaf. A gini score greater than zero implies that samples contained within that node belong to different classes. A gini score of zero means that the node is pure, that within that node only a single class of samples exist. \n",
    "\n",
    "To display the gini score, in function ``export_graphviz`` change the ``impurity`` to True."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_graphviz(tree, out_file=\"tree.dot\", class_names=[\"malignant\", \"benign\"],\n",
    "                feature_names=cancer.feature_names, impurity=True, filled=True)\n",
    "with open(\"tree.dot\") as f:\n",
    "    dot_graph = f.read()\n",
    "display(graphviz.Source(dot_graph))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The gini index at node $n$ is given by $\\sum_{k\\neq k'} p_{nk} * p_{nk'}$, where $k$ and $k'$ are classes and $p_{nk}$ is the probability of class $k$.\n",
    "\n",
    "**Practice.** Verify the gini indexes of the tree above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Entropy "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Intuitively, entropy measures disorder or how messy your data is. In decision trees, the goal is to tidy the data. You try to separate your data and group the samples together in the classes. You know their label since you construct the trees from the training set. You maximize the purity of the groups as much as possible each time you create a new node of the tree (meaning you cut your set in two). Of course, at the end of the tree, you want to have a clear answer.\n",
    "\n",
    "The entroy at node $n$ is given by the following formula: $E(n) = - \\sum_{k}p_{nk} log(p_{nk}) $, where $p_{nk}$ is the probability of class $k$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A set is tidy if it contains only items with the same label, and messy if it is a mix of items with different labels. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = np.random.random(100) # generates 100 random numbers between 0 and 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropy(p):\n",
    "    \n",
    "    return -p*np.log(p)-(1-p)*np.log(1-p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(p, entropy(p))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Information gain\n",
    "\n",
    "Information gain (IG) measures how much information a feature gives us about the class. \n",
    "$$IG(feature) = <\\text{entropy of parent node}> - <\\text{weighted entropy of children}>$$\n",
    "\n",
    "For a mathematical formula, check the related wikipedia page: https://en.wikipedia.org/wiki/Information_gain_in_decision_trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(graphviz.Source(dot_graph))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pe = entropy(159/426) # entropy of parent root\n",
    "le = entropy(23/286) # entropy of left child node\n",
    "re = entropy(136/140) # entropy of right child node\n",
    "print(pe, le, re)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_le = 286/426 # weight of left child node\n",
    "weight_re = 140/426 # weight of right childe node\n",
    "print(weight_le, weight_re)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pe - (weight_le*le + weight_le*re) # GI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split strategies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The gini index and IG are used by Decision Tree Algorithm to construct a Decision Tree. ``DecisionTreeClassifier`` algorithm will always tries to maximize IG or minimize gini. A feature with highest IG will be tested first for splitting the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = DecisionTreeClassifier(criterion=\"gini\", max_depth=4, random_state=12)\n",
    "tree.fit(X_train, y_train)\n",
    "y_pred = tree.predict(X_test)\n",
    "\n",
    "train_score = tree.score(X_train,y_train)\n",
    "test_score = tree.score(X_test,y_test)\n",
    "print(\"Score of train set: {}\".format(train_score))\n",
    "print(\"Score of test set: {}\".format(test_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = DecisionTreeClassifier(criterion=\"entropy\", max_depth=4, random_state=12)\n",
    "tree.fit(X_train, y_train)\n",
    "y_pred = tree.predict(X_test)\n",
    "\n",
    "train_score = tree.score(X_train,y_train)\n",
    "test_score = tree.score(X_test,y_test)\n",
    "print(\"Score of train set: {}\".format(train_score))\n",
    "print(\"Score of test set: {}\".format(test_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters\n",
    "\n",
    "We have already used ``max_depth`` hyperparameter to prune the decision tree. There are others...\n",
    "- ``min_samples_split`` is the minimum number of samples at any node. \n",
    "- ``min_samples_leaf`` is The minimum number of samples required to be at a leaf node. \n",
    "- ``max_features`` is the number of features to consider when looking for the best split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_min_samples_split(X_train, y_train, X_test, y_test, min_samples_split):\n",
    "    train_score = []\n",
    "    test_score = []\n",
    "    for i in min_samples_split:\n",
    "        tree = DecisionTreeClassifier(min_samples_split=i, criterion=\"entropy\", random_state=12)\n",
    "        tree.fit(X_train, y_train)\n",
    "        y_pred = tree.predict(X_test)\n",
    "        train_score.append(tree.score(X_train,y_train))\n",
    "        test_score.append(tree.score(X_test,y_test))\n",
    "    \n",
    "    diff = [abs(x1 - x2) for (x1, x2) in zip(train_score, test_score)]    \n",
    "    index = diff.index(min(diff))\n",
    "    plt.plot(min_samples_split, train_score, label=\"training set\")\n",
    "    plt.plot(min_samples_split, test_score, label=\"test set\") \n",
    "    plt.xlabel(\"min_samples_split\")\n",
    "    plt.ylabel(\"score\")\n",
    "    plt.legend()\n",
    "    \n",
    "    return min_samples_split[index], train_score[index], test_score[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numbers = np.arange(2,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_min_samples_split(X_train, y_train, X_test, y_test, numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_min_samples_leaf(X_train, y_train, X_test, y_test, min_samples_leaf):\n",
    "    train_score = []\n",
    "    test_score = []\n",
    "    for i in min_samples_leaf:\n",
    "        tree = DecisionTreeClassifier(min_samples_leaf=i, criterion=\"entropy\", random_state=12)\n",
    "        tree.fit(X_train, y_train)\n",
    "        y_pred = tree.predict(X_test)\n",
    "        train_score.append(tree.score(X_train,y_train))\n",
    "        test_score.append(tree.score(X_test,y_test))\n",
    "    \n",
    "    diff = [abs(x1 - x2) for (x1, x2) in zip(train_score, test_score)]    \n",
    "    index = diff.index(min(diff))\n",
    "    plt.plot(min_samples_leaf, train_score, label=\"training set\")\n",
    "    plt.plot(min_samples_leaf, test_score, label=\"test set\") \n",
    "    plt.xlabel(\"min_samples_leaf\")\n",
    "    plt.ylabel(\"score\")\n",
    "    plt.legend()\n",
    "    \n",
    "    return min_samples_leaf[index], train_score[index], test_score[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_min_samples_leaf(X_train, y_train, X_test, y_test, numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(cancer.feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numbers = np.arange(1,len(cancer.feature_names)-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_max_features(X_train, y_train, X_test, y_test, max_features):\n",
    "    train_score = []\n",
    "    test_score = []\n",
    "    for i in max_features:\n",
    "        tree = DecisionTreeClassifier(min_samples_leaf=i, criterion=\"entropy\", random_state=12)\n",
    "        tree.fit(X_train, y_train)\n",
    "        y_pred = tree.predict(X_test)\n",
    "        train_score.append(tree.score(X_train,y_train))\n",
    "        test_score.append(tree.score(X_test,y_test))\n",
    "        \n",
    "    diff = [abs(x1 - x2) for (x1, x2) in zip(train_score, test_score)]    \n",
    "    index = diff.index(min(diff))\n",
    "    plt.plot(max_features, train_score, label=\"training set\")\n",
    "    plt.plot(max_features, test_score, label=\"test set\") \n",
    "    plt.xlabel(\"max_features\")\n",
    "    plt.ylabel(\"score\")\n",
    "    plt.legend()\n",
    "    \n",
    "    return max_features[index], train_score[index], test_score[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_max_features(X_train, y_train, X_test, y_test,numbers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature importance\n",
    "\n",
    "``DecisionTreeClassifier`` has an attribute ``feature_importances`` which rates how important each feature is for making decision. ``feature_importances`` is equal 0 for a feature $f$, it means that $f$ is not used at all. If close to 1, then $f$ does a good job at predicting the target. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = DecisionTreeClassifier(max_depth=3, random_state=0)\n",
    "tree.fit(X_train, y_train)\n",
    "tree.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_feature_importances_cancer(model):\n",
    "    n_features = cancer.data.shape[1]\n",
    "    plt.barh(np.arange(n_features), model.feature_importances_, align='center')\n",
    "    plt.yticks(np.arange(n_features), cancer.feature_names)\n",
    "    plt.xlabel(\"Feature importance\")\n",
    "    plt.ylabel(\"Feature\")\n",
    "    plt.ylim(-1, n_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_feature_importances_cancer(tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discussion \n",
    "\n",
    "- Advantages of decision tree: can be visualized, the logic is easy to understand, works with mixed dataset (continuous and discrete features), no need to standarize the data (e.g. one feature in cm and another one in inch).\n",
    "\n",
    "- Disadvantages: Overfitting and poor generalization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression tree\n",
    "\n",
    "Decision trees are used for regression, however, they cannot **extrapolate**, or make predictions outside the range of the target values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.datasets import load_boston"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boston = load_boston()\n",
    "X = pd.DataFrame(boston.data, columns = boston.feature_names)\n",
    "y = pd.DataFrame(boston.target, columns = ['Price'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.3,random_state=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_tree = DecisionTreeRegressor(max_depth=3)\n",
    "reg_tree.fit(X_train, y_train)\n",
    "train_score = reg_tree.score(X_train,y_train)\n",
    "test_score = reg_tree.score(X_test,y_test)\n",
    "print(\"Score of train set: {}\".format(train_score))\n",
    "print(\"Score of test set: {}\".format(test_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR = LinearRegression()\n",
    "LR.fit(X_train, y_train)\n",
    "train_score = LR.score(X_train,y_train)\n",
    "test_score = LR.score(X_test,y_test)\n",
    "print(\"Score of train set: {}\".format(train_score))\n",
    "print(\"Score of test set: {}\".format(test_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[(y_train.min()[0] <= pred and pred <= y_train.max()[0]) for pred in reg_tree.predict(X_test)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[(y_train.min()[0] <= pred and pred <= y_train.max()[0]) for pred in LR.predict(X_test)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question.** In case of regression tree, what would be the predicted values for data outside the range of the training set? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "cross_val_score(reg_tree, X, y, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_val_score(LR, X, y, cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regression tree uses splitting strategies similar to classification tree plus the mse metric as a cost function. The predicted value is the average of the values in a class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_tree.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(reg_tree.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(LR.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random forest\n",
    "\n",
    "A random forest is a collection of decision trees. The random forest is one approach to address the overfitting issue in decision tree. Intuitively, if we build many trees each of which overfit in a different way, we can reduce the amount of overfitting by averaging their results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cancer = load_breast_cancer()\n",
    "\n",
    "X = pd.DataFrame(cancer.data, columns=cancer.feature_names)\n",
    "y = pd.DataFrame(cancer.target, columns=[\"Type\"])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, random_state=412)\n",
    "\n",
    "tree = DecisionTreeClassifier(max_depth=3, random_state=12)\n",
    "tree.fit(X_train, y_train.values.ravel()) # if I use y_train, \n",
    "#I get the following warning \"A column-vector y was passed when a 1d array was expected. \n",
    "#Please change the shape of y to (n_samples,), for example using ravel().\"\n",
    "\n",
    "train_score = tree.score(X_train,y_train)\n",
    "test_score = tree.score(X_test,y_test)\n",
    "print(\"Score of train set (decision tree): {}\".format(train_score))\n",
    "print(\"Score of test set (decision tree): {}\".format(test_score))\n",
    "\n",
    "forest = RandomForestClassifier(n_estimators=5, random_state=12)\n",
    "forest.fit(X_train, y_train.values.ravel())\n",
    "\n",
    "train_score = forest.score(X_train,y_train)\n",
    "test_score = forest.score(X_test,y_test)\n",
    "print(\"Score of train set (random forest): {}\".format(train_score))\n",
    "print(\"Score of test set (random forest): {}\".format(test_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To obtain different decision trees, we need different train datasets. ``RandomForestClassifier`` performs bootstraping, which create several datasets with some points are missing and other are repeated. Next, decision trees are built based on these new datasets. However, the algorithm is **random** meaning that instead of selecting the best feature at each node using gini or entropy, the algorithm randomly generate a subset of the features and selects the best feature from the subset. Hyperparameters  ``n_estimators`` and ``max_features`` specify the number of trees and the max number of randomly selected features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_n_estimators(X_train, y_train, X_test, y_test, n_estimators):\n",
    "    train_score = []\n",
    "    test_score = []\n",
    "    for i in n_estimators:\n",
    "        forest = RandomForestClassifier(n_estimators=i, random_state=12)\n",
    "        forest.fit(X_train, y_train.values.ravel())\n",
    "        train_score.append(forest.score(X_train,y_train))\n",
    "        test_score.append(forest.score(X_test,y_test))\n",
    "    \n",
    "    diff = [abs(x1 - x2) for (x1, x2) in zip(train_score, test_score)]    \n",
    "    index = diff.index(min(diff))\n",
    "    plt.plot(n_estimators, train_score, label=\"training set\")\n",
    "    plt.plot(n_estimators, test_score, label=\"test set\") \n",
    "    plt.xlabel(\"n_estimators\")\n",
    "    plt.ylabel(\"score\")\n",
    "    plt.legend()\n",
    "    \n",
    "    return n_estimators[index], train_score[index], test_score[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numbers = np.arange(1,20)\n",
    "display_n_estimators(X_train, y_train, X_test, y_test, numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_max_features(X_train, y_train, X_test, y_test, max_features):\n",
    "    train_score = []\n",
    "    test_score = []\n",
    "    for i in max_features:\n",
    "        forest = RandomForestClassifier(max_features=i, random_state=12)\n",
    "        forest.fit(X_train, y_train.values.ravel())\n",
    "        train_score.append(forest.score(X_train,y_train))\n",
    "        test_score.append(forest.score(X_test,y_test))\n",
    "    \n",
    "    diff = [abs(x1 - x2) for (x1, x2) in zip(train_score, test_score)]    \n",
    "    index = diff.index(min(diff))\n",
    "    plt.plot(max_features, train_score, label=\"training set\")\n",
    "    plt.plot(max_features, test_score, label=\"test set\") \n",
    "    plt.xlabel(\"n_estimators\")\n",
    "    plt.ylabel(\"score\")\n",
    "    plt.legend()\n",
    "    \n",
    "    return max_features[index], train_score[index], test_score[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numbers = np.arange(1,20)\n",
    "display_max_features(X_train, y_train, X_test, y_test, numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest = RandomForestClassifier(n_estimators=5, random_state=12)\n",
    "forest.fit(X_train, y_train.values.ravel())\n",
    "plot_feature_importances_cancer(forest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boston = load_boston()\n",
    "X = pd.DataFrame(boston.data, columns = boston.feature_names)\n",
    "y = pd.DataFrame(boston.target, columns = ['Price'])\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,random_state=3)\n",
    "\n",
    "reg_forest = RandomForestRegressor(n_estimators=5,max_features=len(boston.feature_names))\n",
    "reg_forest.fit(X_train, y_train.values.ravel())\n",
    "train_score = reg_forest.score(X_train,y_train)\n",
    "test_score = reg_forest.score(X_test,y_test)\n",
    "print(\"Score of train set: {}\".format(train_score))\n",
    "print(\"Score of test set: {}\".format(test_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Discussion\n",
    "\n",
    "Random forests remedy the overfitting issue of decision tree. Furthermore, they share the same advantages as the decision tree (heteregenous data, no preprocessing, etc.), except, they are not easy to visualize and interpret. Time consuming random forests may be parallerized. By specifying ``n_jobs``, we can tell ``RandomForestClassifier`` or ``RandomForestRegressor`` how many CPU cores should be used. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_forest = RandomForestRegressor(n_estimators=3,n_jobs=2)\n",
    "reg_forest.fit(X_train, y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient boosted trees\n",
    "\n",
    "Gradient boosted trees build decision trees in a serial manner, where each tree tries to correct the mistakes of the previous one. The learning rate controls how strongly each tree tries to correct the previous one. Gradient boosted trees use shallow decision trees (depth from 1 to 5). So, each decision tree provides a good prediction on a part of the data and more trees are added to improve the performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cancer = load_breast_cancer()\n",
    "\n",
    "X = pd.DataFrame(cancer.data, columns=cancer.feature_names)\n",
    "y = pd.DataFrame(cancer.target, columns=[\"Type\"])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, random_state=412)\n",
    "\n",
    "boosted = GradientBoostingClassifier(random_state=0) # default n_estimator is 100\n",
    "boosted.fit(X_train, y_train.values.ravel())\n",
    "\n",
    "train_score = boosted.score(X_train,y_train)\n",
    "test_score = boosted.score(X_test,y_test)\n",
    "print(\"Score of train set (gradient boosted trees): {}\".format(train_score))\n",
    "print(\"Score of test set (gradient boosted trees): {}\".format(test_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are likely to be overfitting. To recover, we either lower the ``max_depth`` or lower the ``learning_rate``. According the sklearn documentation, the default values of ``max_depth`` and ``learning_rate`` are 3 and 0.1, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boosted = GradientBoostingClassifier(max_depth=1, random_state=0)\n",
    "boosted.fit(X_train, y_train.values.ravel())\n",
    "\n",
    "train_score = boosted.score(X_train,y_train)\n",
    "test_score = boosted.score(X_test,y_test)\n",
    "print(\"Score of train set (gradient boosted trees): {}\".format(train_score))\n",
    "print(\"Score of test set (gradient boosted trees): {}\".format(test_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boosted = GradientBoostingClassifier(learning_rate=0.01, random_state=0)\n",
    "boosted.fit(X_train, y_train.values.ravel())\n",
    "\n",
    "train_score = boosted.score(X_train,y_train)\n",
    "test_score = boosted.score(X_test,y_test)\n",
    "print(\"Score of train set (gradient boosted trees): {}\".format(train_score))\n",
    "print(\"Score of test set (gradient boosted trees): {}\".format(test_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boston = load_boston()\n",
    "X = pd.DataFrame(boston.data, columns = boston.feature_names)\n",
    "y = pd.DataFrame(boston.target, columns = ['Price'])\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,random_state=3)\n",
    "\n",
    "reg_boosting = GradientBoostingRegressor(n_estimators=20,random_state=0)\n",
    "reg_boosting.fit(X_train, y_train.values.ravel())\n",
    "train_score = reg_boosting.score(X_train,y_train)\n",
    "test_score = reg_boosting.score(X_test,y_test)\n",
    "print(\"Score of train set: {}\".format(train_score))\n",
    "print(\"Score of test set: {}\".format(test_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The book \"Introduction to machine learning with python\" recommend to first select a good ``n_estimator``, then search for optimal ``learning_rate``. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_n_estimators(X_train, y_train, X_test, y_test, n_estimators):\n",
    "    train_score = []\n",
    "    test_score = []\n",
    "    for i in n_estimators:\n",
    "        reg_boosting = GradientBoostingRegressor(n_estimators=i, random_state=0)\n",
    "        reg_boosting.fit(X_train, y_train.values.ravel())\n",
    "        train_score.append(reg_boosting.score(X_train,y_train))\n",
    "        test_score.append(reg_boosting.score(X_test,y_test))\n",
    "    \n",
    "    diff = [(abs(x1 - x2),x1,x2,train_score.index(x1)+1) for (x1, x2) in zip(train_score, test_score) if x1 > 0.9 and x2 > 0.8]  \n",
    "    mi = diff[0]\n",
    "    for d in diff:\n",
    "        if d[0] < mi[0]:\n",
    "            mi = d\n",
    "            \n",
    "    plt.plot(n_estimators, train_score, label=\"training set\")\n",
    "    plt.plot(n_estimators, test_score, label=\"test set\") \n",
    "    plt.xlabel(\"n_estimators\")\n",
    "    plt.ylabel(\"score\")\n",
    "    plt.legend()\n",
    "    \n",
    "    return mi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numbers = np.arange(1,100)\n",
    "display_n_estimators(X_train, y_train, X_test, y_test, numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_boosting = GradientBoostingRegressor(n_estimators=20,learning_rate=0.3,random_state=0)\n",
    "reg_boosting.fit(X_train, y_train.values.ravel())\n",
    "train_score = reg_boosting.score(X_train,y_train)\n",
    "test_score = reg_boosting.score(X_test,y_test)\n",
    "print(\"Score of train set: {}\".format(train_score))\n",
    "print(\"Score of test set: {}\".format(test_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
